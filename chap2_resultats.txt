







## Résultats

### Choisir les paramètres

Comment choisir les paramêtres nous permettant d'obtenir les résultats ?
C'est la première question que nous allons nous poser ici.
Classiquement, lorsque l'on souhaite évaluer les résultats d'une prédiction, on utilise les statistiques découlant des vrai/faux positifs/négatifs.
Commençons par définir chacune de ces catégories dans notre cas :
- Vrai positif (VP) : Un vrai positif est obtenu lorsque le résultat est identique au résultat attendu.
Dans notre cas, une annotation peptidique est un VP si tous les monomères présents dans l'annotation de s2m sont également présent dans l'annotation dans le jeu de test.
Nous aurons donc une couverture et un correctness de 100\%.
- Faux positif (FP) : Un faux positif est obtenu lorsque le résultat parait correct mais qu'il diffère du résultat attendu.
Dans notre cas, une annotation est un FP si tout ses atomes sont couverts par l'annotation mais que celle-ci diffère de celle du jeu test.
Nous aurons donc une couverture de 100\% et un correctness inférieur à 100\%
- Faux négatif (FN) : Un faux négatif est obtenu lorsque le résultat ne parait pas correct alors qu'il est possible de l'obtenir.
Dans notre cas, une annotation est un FN lorsque nous n'arrivons pas à produire une annotation complète du peptide.
C'est à dire que nous aurons une couverture et une correctness inférieure à 100\%.
- Vrai négatif (VN) : Un vrai négatif est obtenu lorsque le résultat ne parait pas correct et qu'il n'est pas possible d'en obtenir un.
Dans notre cas, ceci n'est pas possible.
Il est toujours possible d'obtenir une annotation correcte vu qu'elles sont toutes présentes dans le jeu test.


Pour débuter le choix des paramètres, nous n'allons pas du tout prendre en compte le temps d'exécution.
Les but ici est d'exposer la qualité des résultats uniquement.
Pour cela nous allons prendre comme indicateurs La couverture atomique moyenne, le corectness atomique moyen et les taux de VP/FP/FN (et donc la sensibilité).
Nous allons faire varier le paramètre du nombre de tour de la boucle light ainsi que la profondeur de modulation pour le pavage avec modulation.
Nous testerons également les deux algorithmes algorithmes de pavage.


Tableau de chiffres pour les exécutions


Comme nous voyons sur le tableau de la figure \ref{}, l'algorithme de pavage par optimisation linéaire n'est pas du tout sensible au changement de paramètres.
Ceci s'explique par le fait qu'il n'a besoin que d'une seule phase light pour parvenir à son optimal local.
En effet, dans certains cas, le problème et tout de suite résolu après la première phase de pavage succédant l'isomorphisme light car toutes les briques ont été correctement découvertes.
Dans les autres cas, l'algorithme du MIP a tellement cherché à optimiser les nombre d'atomes couverts à la suite du premier pavage, que la solution intermédiaire est trop distante de la vraie solution pour pouvoir être rattrapée.

Pour le pavage heuristique, la sensibilité aux paramètres est bien différente.
On peut voir que augmenter le nombre de modulations augmente le nombre de bons résultats.
Le nombre de vrais positifs augmente significativement en passant le paramètre de 1 à 2.
Le paramètre de nombre de boucle light n'a que très peu d'influence et vient seulement compléter 3 résultats sur les données Norine.

En conparant les résultats des deux algorithmes, on s'apperçoit que l'algorithme comprenant l'heuristique de pavage obtient de meilleurs résultats (pour une modulation >= 3) que l'algorithme incluant un pavage exact.
Encore une fois ce résultat s'explique par le fait que le pavage exact va trop loin dans l'optimisation.
Si aucune solution couvrante n'est possible avec les résidus issus de l'isomorphisme strict, alors le pavage maximal exact pourra potentiellement effectuer des solutions optimisées farfelues.
Dans ce cas, la recherche de résidus par isomorphisme sert peu car les trous dans l'annotation ont été déplacés par l'optimisation.
Il n'est souvent plus possible de construire l'annotation.


Pour achever la comparaison, nous devons ajouter l'analyse du temps de calcul.

TODO


### Analyse des résultats

Vous pourrez trouver tous les résultats sur les polymères testés à ces adresses :
- CCD : www.TODO.com
- Norine : www.TODO.com

TODO : schéma des résultats globaux de s2m.

Revenons un peu sur les chiffres qui ont été présentés dans le tableau TODO.
Sur le schéma TODO, on peut lire les répartitions des peptides au sein des différentes catégories pour les deux jeux de données.
Dans les deux cas les résultats sont très bons.
Environ 74% des annotations peptidiques issus de Norine et 85% de celles de CCD sont entiérement retrouvées par le logiciel.
Mais il faut se rappeler que les annotations ne sont plus considérées comme correctnes dès lors qu'au moins un monomère est faux.
En regrdant le taux d'atomes correctement attribués au sein des peptides, dans ce cas, le taux de réussite augmente à plus de 93\% pour les annotations de Norine et plus de 98\% pour CCD.

Mais même ces très bons taux de résussite ne sont pas représentatif de la qualité des annotations.
En effet, en analysant les résultats de plus près, nous nous sommes aperçu qu'il était possible de détecter des erreurs au sein des bases de données.
Analysons ensemble plusieurs cas que nous allons mettre en avant ici pour voir les différents comprendre les erreurs.


#### Des structures peptidiques atomiques fausses

TODO : figure s2m enniati I

Beaucoup d'annotations fausses proviennent d'erreurs de structures atomiques pour les peptides.
Prenons l'exemple de l'``enniatin I''.
L'annotation en sortie de s2m présente une couverture à 100\% mais un correctness de 66\%.
En regardant les 3 listes de monomères, on peut s'appercevoir que l'annotation attendue comporte deux monomères nommés Hmp alors que le logiciel trouve deux 4Me-Hva.
Les deux monomères se ressemblant, il est fort probable que soit l'anotation monomérique soit l'anotation atomique ai été mal entrée.
Pour connaitre le fin mot de l'histoire, remontons les sources des données.
Sur la page Norine de la molécule, nous trouvons un lien vers Pubchem pour nous permettre d'obtenir la structure atomique et un lien vers la publication qui nous permet d'obtenir la structure monomérique.

TODO : Figure structures PubChem et publi

En regardant la molécule présente sur PubChem, nous pouvons constater que c'est effectivement la structure atomique qui a été utilisée pour le test.
En lisant désormais la publication, on s'apperçoit que la structure monomérique correspond à ce qui est présent sur Norine.
Accompagnant cette annotation monomérique est présent un schéma de la structure atomique venant confirmer la structure monomérique.
Sans aucun doute, l'erreur provient des données issues de PubChem.
A priori le lien PubChem entré sur Norine n'est pas le bon et pointe vers un peptide similaire.

Nous n'avons pas fini de traiter manuellement toutes les données issues de s2m mais au moins une erreur sur deux est de ce genre.


#### Des structures atomiques atomiques fausses

TODO : Figure de la dolastatin 10

Lorsque le taux de couverture de l'annotation issue de s2m est inférieur à 100\%, par définition, au moins un monomère n'a pu être trouvé.
Il est possible que ce monomère n'ait jamais été répertorié, que la structure atomique du peptide soit incorrecte ou que la structure d'un monomère le soit également.
Dans le cas de l'annotation de la dolastatin, c'est une erreur de structure atomique qui s'est glissée dans la base Norine.
Le monomère Dap qui est sensé être présent n'est pas reconnu car l'atome d'azote n'est pas placé au même endroit au sein du monomère seul et du monomère dans le peptide.
En cherchant sur Norine on peut s'appercevoir qu'aucun autre peptide de la base ne comporte ce monomère.
Le changement de conformation n'est donc probablement pas du à une modification de la molécule mais plutôt à une erreur d'annotation.
En parcourant l'article qui publia le peptide et la structure atomique présente sur PubChem, on s'apperçoit que c'est une erreur uniquement sur Norine.


#### Erreurs d'annotations

TODO : Figure de la fengycine A (ci.inria)

Il arrive parfois que des molécules soient trompeuses.
En entrant à la main les annotations, il est possible de confondre un monomère avec un de ses dérivés proches.
C'est ce qui est arrivé avec la fengycine A.
L'annotation effectuée par s2m détecte un monomère Gln alors que l'annotation présente dans Norine détecte un Glu.
En effectuant à nouveau toutes les opérations de vérification de la structure atomique et monomérique, on s'apperçoit rapidement que l'article donne raison à s2m.
Cette fois-ci c'est l'annotation monomérique présente dans Norine qui est à changer pour obtenir une information juste.


#### Les équivalences

TODO : Schéma cyclotheonamide E

Le dernier type d'erreurs d'annotations commises par s2m est quand a lui strictement dut à l'algorithme et pas aux données.
C'est un problème d'annotations équivalentes.
Comme nous le voyons sur le schéma de la ``cyclotheonamide E'', le peptide est couvert à 100\%.
De plus, l'annotation présente dans Norine propose deux monomères visuellement très proches des monomères suggérés par s2m.
En regardant dans le détail, on peut observer que la formylation pourrait a priori s'effectuer soit sur le monomère Arg soit sur l'Ile.
Dans les deux cas, l'annotation reste couvrante à 100\%.
N'ayant aucun moyen algorithmique de faire la différence, ici s2m a choisit une solution au hasard.
Pour connaitre l'annotation réelle, il faut remonter à la production du peptide pour comprendre les mécanismes de modifications de monomère qui sont ici en jeu.
Cette erreur est présente moins d'une dizaine de fois dans les données déjà vérifiées.


#### Et CCD dans tout ça ?

TODO : Figure équivalence obvious

Je n'ai effectivement parlé ici que des erreurs d'annotation présentes dans Norine.
Pour nous, il est très facile de vérifier toutes les informations car de nombreux liens vers les données initiales sont présents et normalisés.
Au sein des données de issues de CCD, nous détectons le même genre de problème que dans Norine mais sans pouvoir les analyser en profondeur.
Pour résumer, il est possible pour des données inconnues, de détecter la présence d'erreurs mais sans pour autant pouvoir expliquer pourquoi.
Seules les erreurs dues aux équivalences sont facilement détectables (voir par exemple TODO).


## Conclusion

TODO






























